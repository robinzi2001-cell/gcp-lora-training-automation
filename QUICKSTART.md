# GCP LoRA Training - Quick Start Guide

## ğŸ“¦ Installation

### 1. GitHub-Repo klonen ODER ZIP herunterladen
```bash
# Option A: Git Clone
git clone https://github.com/robinzi2001-cell/gcp-lora-training-automation.git
cd gcp-lora-training-automation

# Option B: Manuell hochladen
# Die 7 Dateien sind bereits in /tmp/gcp-lora-automation/ erstellt
# Du kannst sie manuell ins GitHub-Repo hochladen Ã¼ber die Web-UI
```

### 2. Dependencies installieren
```bash
pip install -r requirements.txt
```

### 3. Google Cloud Setup
```bash
# gcloud installieren (falls nicht vorhanden)
curl https://sdk.cloud.google.com | bash

# Authentifizieren
gcloud auth login

# Projekt setzen
gcloud config set project lora567
```

## ğŸš€ Workflow

### Schritt 1: VM erstellen (mit 80GB GPU)
```bash
python 1_provision_vm.py
```
**Wichtig:** BenÃ¶tigt GPU-Quotas in GCP!
**Kosten:** ~$3-4/Stunde fÃ¼r A100

### Schritt 2: Bilder vorbereiten
```bash
# Lege deine Rohbilder in ./raw_data/
mkdir raw_data
cp /pfad/zu/deinen/bildern/*.jpg raw_data/

# Starte Vorverarbeitung
python 2_preprocess_images.py --keyword ciri567
```

Das Skript:
- Fragt dein Keyword ab (z.B. "ciri567")
- Benennt Bilder um: keyword_0001.jpg, keyword_0002.jpg...
- Generiert automatische Captions mit BLIP
- Analysiert BildqualitÃ¤t
- Erstellt Metadaten

### Schritt 3: Training starten
```bash
# Verbinde mit VM
gcloud compute ssh lora-training-vm --zone us-central1-a

# Upload Daten zur VM
gcloud compute scp --recurse ./processed_data lora-training-vm:/home/lora_training/ --zone us-central1-a

# Auf VM: Training starten
python 3_train_lora.py
```

Training lÃ¤uft automatisch:
- Installiert Kohya-ss Scripts
- LÃ¤dt SDXL Base Model (~6GB, einmalig)
- Trainiert LoRA mit optimalen Settings
- Speichert Modelle als .safetensors

## ğŸ¯ MCP-Server (fÃ¼r direkte Claude-Steuerung)

### Setup
1. FÃ¼ge zu deiner MCP-Config hinzu (`~/.config/claude/mcp.json`):
```json
{
  "mcpServers": {
    "gcp-lora": {
      "command": "python",
      "args": ["/pfad/zu/mcp_server.py"],
      "env": {
        "GCP_PROJECT": "lora567",
        "GCP_ZONE": "us-central1-a"
      }
    }
  }
}
```

2. VerfÃ¼gbare Tools in Claude:
- `provision_vm` - VM erstellen
- `upload_images` - Bilder hochladen
- `preprocess_images` - Bilder vorbereiten
- `start_training` - Training starten
- `get_training_status` - Status abfragen
- `download_lora` - Modell herunterladen
- `stop_vm` - VM stoppen (Kosten sparen!)

## ğŸ’° Kosten-Management

**Sehr wichtig:** VM nach Training STOPPEN!

```bash
# VM stoppen (behÃ¤lt Daten)
gcloud compute instances stop lora-training-vm --zone us-central1-a

# VM wieder starten
gcloud compute instances start lora-training-vm --zone us-central1-a

# VM komplett lÃ¶schen
gcloud compute instances delete lora-training-vm --zone us-central1-a
```

### Kosten-Ãœbersicht:
- **A100 (40GB)**: ~$3-4/h
- **L4 (24GB)**: ~$0.70/h  
- **T4 (16GB)**: ~$0.35/h

## ğŸ¨ Output nutzen

Nach Training findest du LoRA-Modelle in `/home/lora_training/output/`

### Download:
```bash
gcloud compute scp lora-training-vm:/home/lora_training/output/*.safetensors ./ --zone us-central1-a
```

### Verwendung in ComfyUI/A1111:
1. Kopiere `.safetensors` nach `models/lora/`
2. Im Prompt: `<lora:dein_keyword_lora:0.8>`
3. Nutze dein Keyword: `ciri567, detailed portrait, ...`

## ğŸ› Troubleshooting

### GPU-Quota-Fehler
â†’ Beantrage Quota: https://console.cloud.google.com/iam-admin/quotas
â†’ Oder nutze T4 statt A100 (gÃ¼nstiger, verfÃ¼gbar)

### Out-of-Memory
â†’ Reduziere `batch_size` auf 1 in `3_train_lora.py`
â†’ Aktiviere `gradient_checkpointing`

### NVIDIA-Treiber fehlen
```bash
# Auf VM:
sudo apt-get install --reinstall cuda-drivers
nvidia-smi  # Sollte GPU zeigen
```

## ğŸ“ Datei-Struktur

```
gcp-lora-automation/
â”œâ”€â”€ 1_provision_vm.py       # VM mit GPU erstellen
â”œâ”€â”€ 2_preprocess_images.py  # Bilder vorbereiten + Captions
â”œâ”€â”€ 3_train_lora.py          # SDXL LoRA Training
â”œâ”€â”€ mcp_server.py            # MCP-Integration fÃ¼r Claude
â”œâ”€â”€ requirements.txt         # Python Dependencies
â”œâ”€â”€ README.md                # VollstÃ¤ndige Doku
â””â”€â”€ .gitignore
```

## âš ï¸ Wichtige Hinweise

1. **Kosten:** GPU-VMs sind TEUER! Immer nach Training stoppen.
2. **Quotas:** GPU-Quotas vorher beantragen (kann 24h dauern).
3. **Bilder:** Mindestens 20-30 hochwertige, diverse Bilder fÃ¼r gute Results.
4. **Rechte:** Nur Bilder verwenden, fÃ¼r die du Rechte hast.
5. **Backup:** Wichtige Modelle regelmÃ¤ÃŸig herunterladen.

## ğŸ“ Was die Skripte tun

### 1_provision_vm.py
âœ“ Erstellt VM mit A100 GPU
âœ“ Installiert NVIDIA-Treiber + CUDA
âœ“ Installiert Docker + NVIDIA Container Toolkit
âœ“ Installiert Python + ML-Libraries
âœ“ Richtet Firewall-Regeln ein

### 2_preprocess_images.py  
âœ“ Fragt Custom Keyword ab
âœ“ Benennt Bilder einheitlich um
âœ“ Generiert automatische Captions (BLIP)
âœ“ Analysiert BildqualitÃ¤t
âœ“ Erstellt Metadaten + Caption-Dateien

### 3_train_lora.py
âœ“ Installiert Kohya-ss Training Scripts
âœ“ LÃ¤dt SDXL Base Model
âœ“ Konfiguriert optimales Training
âœ“ Trainiert LoRA-Modell
âœ“ Speichert Checkpoints + finales Modell

---

**Viel Erfolg beim Training! ğŸ¯**

Bei Fragen: GitHub Issues erstellen
